{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "445df666-6d91-4da7-8abe-813b3b97ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9056e16e-74e1-4af5-9b2f-41d100a2f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.paths import list_images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from augmentations import avg_aug\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b52e3b0-d4a4-4499-8cf6-bee234014004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function_with_DA(impath):\n",
    "    # instantiate augmentation here to overcome \"not-changing-random-seed\" bug\n",
    "    # this could lead to an speed decrease or an overheap, dont know\n",
    "    aug = avg_aug() # think about deleting aug after use\n",
    "    \n",
    "    # image reading\n",
    "    image = tf.io.read_file(impath)\n",
    "    image = tf.io.decode_png(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, shape)\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image = tf.numpy_function(func=aug.augment_image, inp=[image], Tout=tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.\n",
    "    \n",
    "    # image = tf.clip_by_value(image, -1, 1)\n",
    "    \n",
    "    # label setting\n",
    "    _split = tf.strings.split(impath, sep=os.sep)\n",
    "    _cls = _split[-4]\n",
    "    \n",
    "    # if 'bonafide' in _split:\n",
    "    #     lb = tf.cast([0, 1], tf.float32)\n",
    "    # else:\n",
    "    #     lb = tf.cast([1, 0], tf.float32)\n",
    "    \n",
    "    # 4th element is the class id\n",
    "    if _cls == 'bonafide':\n",
    "        lb = tf.cast([0, 1], tf.float32)\n",
    "    else:\n",
    "        lb = tf.cast([1, 0], tf.float32)\n",
    "    \n",
    "    return image, lb\n",
    "\n",
    "def _parse_function_without_DA(impath):\n",
    "    # image reading\n",
    "    image_string = tf.io.read_file(impath)\n",
    "    image_decoded = tf.io.decode_png(image_string, channels=3)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    image = tf.image.resize(image, shape)\n",
    "    image = image / 255.\n",
    "    \n",
    "    # image = tf.clip_by_value(image, -1, 1)\n",
    "    \n",
    "    # label setting\n",
    "    _split = tf.strings.split(impath, sep=os.sep)\n",
    "    _cls = _split[-4]\n",
    "    \n",
    "    # if 'bonafide' in _split:\n",
    "    #     lb = tf.cast([0, 1], tf.float32)\n",
    "    # else:\n",
    "    #     lb = tf.cast([1, 0], tf.float32)\n",
    "    \n",
    "    # 4th element is the class id\n",
    "    if _cls == 'bonafide':\n",
    "        lb = tf.cast([0, 1], tf.float32)\n",
    "    else:\n",
    "        lb = tf.cast([1, 0], tf.float32)\n",
    "    \n",
    "    \n",
    "    return image, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57a56c36-b65b-4247-aaab-39f71653c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_classes = ('attack', 'bonafide')\n",
    "_bf_index = _classes.index('bonafide')\n",
    "shape = (224, 224)\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aad65790-a2f7-42e4-943f-04565eb7b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'flickr': '../data/02_intermediate/flickr',\n",
    "    'splunk': '../data/02_intermediate/splunk'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3f6b6d7-0c29-4d3f-8afd-14842683a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return tf.data\n",
    "def load_dataset(\n",
    "    db_dict=None, db_key='flickr', multiclass=False, \n",
    "    data_augmentation=False, shape=(224, 224), color='rgb', \n",
    "    load_csv=False, class_weights=False, batch_size=16\n",
    "):\n",
    "    \n",
    "    db_dir = db_dict.get(db_key)\n",
    "    _classes = ('attack', 'bonafide')\n",
    "    _bf_index = _classes.index('bonafide')\n",
    "    imlist = [*list_images(db_dir)]\n",
    "    bf_list, att_list = [], []\n",
    "    \n",
    "    for imdir in imlist:\n",
    "        if _classes[_bf_index] in imdir.split(os.sep): # if 'bonafide' in imdir\n",
    "            bf_list.append(imdir)\n",
    "        else:\n",
    "            att_list.append(imdir)\n",
    "    \n",
    "    bf_y = np.ones(len(bf_list))\n",
    "    att_y = np.zeros(len(att_list))\n",
    "    \n",
    "    # split|load data into train|test|val\n",
    "    X = np.concatenate([att_list, bf_list])\n",
    "    y = np.concatenate([bf_y, att_y])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    # train dataset\n",
    "    train_dataset = tf.cast(X_train, dtype=tf.string)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "    train_dataset = train_dataset.shuffle(batch_size**2)\n",
    "    train_dataset = train_dataset.map(_parse_function_with_DA, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset = train_dataset.cache()\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    \n",
    "    # val dataset\n",
    "    val_dataset = tf.cast(X_val, dtype=tf.string)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices(val_dataset)\n",
    "    val_dataset = val_dataset.shuffle(batch_size**2)\n",
    "    val_dataset = val_dataset.map(_parse_function_without_DA, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.cache()\n",
    "    val_dataset = val_dataset.batch(1)\n",
    "    \n",
    "    # test dataset\n",
    "    test_dataset = tf.cast(X_test, dtype=tf.string)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset)\n",
    "    test_dataset = test_dataset.shuffle(batch_size**2)\n",
    "    test_dataset = test_dataset.map(_parse_function_without_DA, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.cache()\n",
    "    test_dataset = test_dataset.batch(1)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc9e730e-e585-4c6f-b182-3ff25b42a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = load_dataset(db_dict=datasets, db_key='splunk', batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d07b6da-2bb7-42fa-a029-8f295c07d5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14958, 4986, 4986)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(test_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957ec90-5a0d-4eeb-b865-c265a2f7b33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████████████████████                                                                                                                                         | 2841/14958 [01:48<20:36,  9.80it/s]"
     ]
    }
   ],
   "source": [
    "y_train = [ np.argmax(lb[0]) for im, lb in tqdm(train_ds) ]\n",
    "y_test = [ np.argmax(lb[0]) for im, lb in tqdm(test_ds) ]\n",
    "y_val = [ np.argmax(lb[0]) for im, lb in tqdm(val_ds) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e04e38-4c72-4a03-a623-6c9c0aee4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True), np.unique(y_val, return_counts=True), np.unique(y_test, return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
